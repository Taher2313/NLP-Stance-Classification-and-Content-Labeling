{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from tashaphyne.stemming import ArabicLightStemmer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_text,dev_category,dev_stance = utils.read_dataset(\"Dataset/dev.csv\")\n",
    "train_text,train_category,train_stance = utils.read_dataset(\"Dataset/train.csv\")\n",
    "test_ids,test_text=utils.read_testset(\"Dataset/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dev_text =  pd.concat([train_text,dev_text])\n",
    "train_dev_stance =  pd.concat([train_text,dev_text])\n",
    "train_dev_category =  pd.concat([train_text,dev_text])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose preprocessing methods\n",
    "* change any method if needed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ArListem = ArabicLightStemmer()\n",
    "\n",
    "cleaner = utils.combine_pipe([utils.remove_urls,utils.remove_lfs,utils.remove_under_scores,utils.remove_user_tag])  \n",
    "normalizer = ArListem.normalize\n",
    "tokenizer = ArListem.tokenize\n",
    "\n",
    "def stemmer(tokens):\n",
    "    stems=[None]*len(tokens)\n",
    "    for i,token in enumerate(tokens):\n",
    "        stems[i]=ArListem.light_stem(token)\n",
    "    return stems\n",
    "\n",
    "# def stemmer(tokens):\n",
    "#     stems=[None]*len(tokens)\n",
    "#     for i,token in enumerate(tokens):\n",
    "#         stems[i]=nltk.stem.ARLSTem2().stem(token)\n",
    "#     return stems\n",
    "\n",
    "# preprocess = utils.combine_pipe([cleaner,normalizer,tokenizer,stemmer])\n",
    "preprocess = utils.combine_pipe([cleaner,normalizer,tokenizer])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preprocessed_text = train_text.apply(preprocess)\n",
    "dev_preprocessed_text = dev_text.apply(preprocess)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "520/520 [==============================] - ETA: 0s - loss: 0.9859 - accuracy: 0.4393"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_15_layer_call_fn, lstm_cell_15_layer_call_and_return_conditional_losses, lstm_cell_16_layer_call_fn, lstm_cell_16_layer_call_and_return_conditional_losses, lstm_cell_17_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "520/520 [==============================] - 118s 223ms/step - loss: 0.9859 - accuracy: 0.4393 - val_loss: 0.6660 - val_accuracy: 0.6810\n",
      "32/32 [==============================] - 3s 63ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.15      0.56      0.24        70\n",
      "           0       0.17      0.08      0.11       126\n",
      "           1       0.92      0.79      0.85       804\n",
      "\n",
      "    accuracy                           0.68      1000\n",
      "   macro avg       0.42      0.47      0.40      1000\n",
      "weighted avg       0.77      0.68      0.71      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from word_embeddings import embeddings\n",
    "from lstm import LSTM\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "train_stance =  train_stance + 1\n",
    "dev_stance =  dev_stance + 1\n",
    "\n",
    "lstm = LSTM(\n",
    "    embeddings = embeddings,\n",
    "    train_x = train_preprocessed_text.copy(),\n",
    "    dev_x = dev_preprocessed_text.copy(),\n",
    "    train_label = train_stance.copy(),\n",
    "    dev_label = dev_stance.copy(),\n",
    "    output_size=3,\n",
    "    learning_rate=0.0001,\n",
    "    label=1,\n",
    "    path=\"model/\",\n",
    "    epochs=1   \n",
    ")\n",
    "predictions = lstm.get_predictions()\n",
    "\n",
    "train_stance = train_stance - 1\n",
    "dev_stance = dev_stance - 1\n",
    "print(classification_report(dev_stance, predictions ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "map = {\n",
    "    \"advice\": 0,\n",
    "    \"celebrity\": 1,\n",
    "    \"info_news\": 2,\n",
    "    \"others\": 3,\n",
    "    \"personal\": 4,\n",
    "    \"plan\": 5,\n",
    "    \"requests\": 6,\n",
    "    \"restrictions\": 7,\n",
    "    \"rumors\": 8,\n",
    "    \"unrelated\": 9\n",
    "}\n",
    "train_category_num = train_category.apply(lambda x: map[x])\n",
    "dev_category_num = dev_category.apply(lambda x: map[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1130/1130 [==============================] - ETA: 0s - loss: 1.9674 - accuracy: 0.2279"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_21_layer_call_fn, lstm_cell_21_layer_call_and_return_conditional_losses, lstm_cell_22_layer_call_fn, lstm_cell_22_layer_call_and_return_conditional_losses, lstm_cell_23_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model2/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1130/1130 [==============================] - 222s 194ms/step - loss: 1.9674 - accuracy: 0.2279 - val_loss: 2.0393 - val_accuracy: 0.1450\n",
      "32/32 [==============================] - 3s 63ms/step\n"
     ]
    }
   ],
   "source": [
    "lstm = LSTM(\n",
    "    embeddings = embeddings,\n",
    "    train_x = train_preprocessed_text.copy(),\n",
    "    dev_x = dev_preprocessed_text.copy(),\n",
    "    train_label = train_category_num.copy(),\n",
    "    dev_label = dev_category_num.copy(),\n",
    "    output_size=10,\n",
    "    learning_rate=0.0001,\n",
    "    label=0,\n",
    "    path=\"model2/\",\n",
    "    epochs=1   \n",
    ")\n",
    "predictions = lstm.get_predictions()\n",
    "# print(classification_report(dev_category_num, predictions ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      advice       0.09      0.50      0.16        10\n",
      "   celebrity       0.84      0.76      0.80       145\n",
      "   info_news       0.00      0.00      0.00       545\n",
      "      others       0.00      0.00      0.00        17\n",
      "    personal       0.00      0.00      0.00       128\n",
      "        plan       0.00      0.00      0.00        82\n",
      "    requests       0.03      0.70      0.07        20\n",
      "restrictions       0.50      0.50      0.50         2\n",
      "      rumors       0.04      0.67      0.07        15\n",
      "   unrelated       0.04      0.14      0.06        36\n",
      "\n",
      "    accuracy                           0.14      1000\n",
      "   macro avg       0.15      0.33      0.16      1000\n",
      "weighted avg       0.13      0.14      0.12      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "reverse_map = {\n",
    "    0: \"advice\",\n",
    "    1: \"celebrity\",\n",
    "    2: \"info_news\",\n",
    "    3: \"others\",\n",
    "    4: \"personal\",\n",
    "    5: \"plan\",\n",
    "    6: \"requests\",\n",
    "    7: \"restrictions\",\n",
    "    8: \"rumors\",\n",
    "    9: \"unrelated\"\n",
    "}\n",
    "\n",
    "predictions_list = predictions.tolist()\n",
    "predictions_list = [reverse_map[x] for x in predictions_list]\n",
    "# dev_category_list = dev_category.tolist()\n",
    "# dev_category_list = [reverse_map[x] for x in dev_category_list]\n",
    "\n",
    "print(classification_report(dev_category, predictions_list ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Vocab\n",
    "* unique words in training set\n",
    "* remove stopwords as they are not helpful in classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27529"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Remove Arabic Stop Words from vocab \"\"\"\n",
    "arb_stopwords = set(nltk.corpus.stopwords.words(\"arabic\"))\n",
    "\n",
    "vocab = utils.build_vocab(train_preprocessed_text)\n",
    "vocab = utils.remove_words_in(vocab,arb_stopwords)\n",
    "\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose Feature extractor \n",
    "* we will have more than one feature extractor \n",
    "* choose one of them here\n",
    "* feature extractor takes a preprocessed tweets and return their features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import freq_feature_extractor \n",
    "# feature_extractor = freq_feature_extractor.build_feature_extractor(train_preprocessed_text,train_stance)\n",
    "\n",
    "# import bog_feature_extractor\n",
    "# feature_extractor = bog_feature_extractor.build_feature_extractor(train_preprocessed_text)\n",
    "\n",
    "\n",
    "import tfidf_feature_extractor\n",
    "feature_extractor = tfidf_feature_extractor.build_feature_extractor(train_preprocessed_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_X = feature_extractor(train_preprocessed_text)\n",
    "\n",
    "dev_X = feature_extractor(dev_preprocessed_text)\n",
    "\n",
    "test_X=feature_extractor(test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose Stance Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMOTE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "train_stance_X   = train_X\n",
    "train_category_X = train_X\n",
    "\n",
    "train_stance_Y = train_stance\n",
    "train_category_Y = train_category\n",
    "\n",
    "dev_stance_Y = dev_stance\n",
    "dev_category_Y = dev_category\n",
    "\n",
    "\n",
    "# smote = SMOTE(random_state=42,)\n",
    "# train_stance_X , train_stance_Y = smote.fit_resample(train_X, train_stance_Y)\n",
    "\n",
    "\n",
    "# smote = SMOTE(random_state=42)\n",
    "# train_category_X , train_category_Y = smote.fit_resample(train_X, train_category_Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler,MaxAbsScaler\n",
    "# from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "# scaler  = make_pipeline(StandardScaler(with_mean=False),MaxAbsScaler())\n",
    "# train_X = scaler.fit_transform(train_stance_X)\n",
    "# dev_X   = scaler.transform(dev_X)\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB \n",
    "stance_model = MultinomialNB(alpha=0.31)\n",
    "stance_model = stance_model.fit(train_stance_X, train_stance_Y)\n",
    "\n",
    "\n",
    "# from sklearn.naive_bayes import GaussianNB \n",
    "# stance_model = GaussianNB()\n",
    "# stance_model = stance_model.fit(train_stance_X.toarray(), train_stance_Y)\n",
    "\n",
    "# from sklearn.svm import LinearSVC\n",
    "# stance_model = LinearSVC()\n",
    "# stance_model = stance_model.fit(train_stance_X, train_stance_Y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Choose Category Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler,MaxAbsScaler\n",
    "# from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "# scaler  = make_pipeline(StandardScaler(with_mean=False),MaxAbsScaler())\n",
    "\n",
    "# train_X = scaler.fit_transform(train_X)\n",
    "# dev_X   = scaler.transform(dev_X)\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB \n",
    "category_model = MultinomialNB(alpha=0.31)\n",
    "category_model = category_model.fit(train_category_X, train_category_Y)\n",
    "\n",
    "\n",
    "# from sklearn.naive_bayes import GaussianNB \n",
    "# category_model = GaussianNB()\n",
    "# category_model = category_model.fit(train_category_X.toarray(), train_category_Y)\n",
    "\n",
    "# from sklearn.svm import LinearSVC\n",
    "# category_model = LinearSVC()\n",
    "# category_model = category_model.fit(train_category_X, train_category_Y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing Alpha for Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max f1= 0.5642371426685152 @ alpha= 0.016000000000000007\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.33      0.61      0.43        38\n",
      "           0       0.30      0.46      0.36        83\n",
      "           1       0.95      0.86      0.90       879\n",
      "\n",
      "    accuracy                           0.82      1000\n",
      "   macro avg       0.53      0.64      0.56      1000\n",
      "weighted avg       0.87      0.82      0.84      1000\n",
      "\n",
      "max f1= 0.32194378665710416 @ alpha= 0.005\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      advice       0.20      0.67      0.31         3\n",
      "   celebrity       0.79      0.87      0.83       132\n",
      "   info_news       0.82      0.71      0.76       632\n",
      "      others       0.06      0.12      0.08         8\n",
      "    personal       0.57      0.55      0.56       132\n",
      "        plan       0.09      0.15      0.11        46\n",
      "    requests       0.10      0.12      0.11        16\n",
      "restrictions       0.00      0.00      0.00         0\n",
      "      rumors       0.07      0.12      0.09         8\n",
      "   unrelated       0.31      0.48      0.37        23\n",
      "\n",
      "    accuracy                           0.66      1000\n",
      "   macro avg       0.30      0.38      0.32      1000\n",
      "weighted avg       0.71      0.66      0.68      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB(alpha=0.005)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB(alpha=0.005)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB(alpha=0.005)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score,classification_report\n",
    "\n",
    "\n",
    "def get_best_NB(train_X,train_Y,dev_X,dev_Y):\n",
    "    best_alpha = 0\n",
    "    max_f1 = 0\n",
    "    best_model = None\n",
    "\n",
    "    alpha=.001\n",
    "    while alpha<1:\n",
    "        model = MultinomialNB(alpha=alpha)\n",
    "        model = model.fit(train_X, train_Y)\n",
    "        predicted_y = model.predict(dev_X)\n",
    "        \n",
    "        f1 = f1_score(dev_Y,predicted_y,average='macro')\n",
    "        \n",
    "        if f1 > max_f1:\n",
    "            max_f1     = f1\n",
    "            best_alpha = alpha\n",
    "            best_model = model\n",
    "        alpha+=.001\n",
    "    print(f\"max f1= {max_f1} @ alpha= {best_alpha}\")\n",
    "    print(classification_report(best_model.predict(dev_X),dev_Y))\n",
    "\n",
    "    return best_model\n",
    "\n",
    "get_best_NB(train_stance_X,train_stance_Y,dev_X,dev_stance_Y)\n",
    "get_best_NB(train_category_X,train_category_Y,dev_X,dev_category_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Stance Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.40      0.03      0.05        70\n",
      "           0       0.65      0.13      0.22       126\n",
      "           1       0.82      0.99      0.90       804\n",
      "\n",
      "    accuracy                           0.81      1000\n",
      "   macro avg       0.62      0.38      0.39      1000\n",
      "weighted avg       0.77      0.81      0.75      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import classification_report,f1_score\n",
    "print(classification_report(dev_stance_Y,stance_model.predict(dev_X.toarray())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Test category Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      advice       0.00      0.00      0.00        10\n",
      "   celebrity       0.90      0.77      0.83       145\n",
      "   info_news       0.66      0.96      0.78       545\n",
      "      others       0.00      0.00      0.00        17\n",
      "    personal       0.67      0.37      0.47       128\n",
      "        plan       0.00      0.00      0.00        82\n",
      "    requests       0.00      0.00      0.00        20\n",
      "restrictions       0.00      0.00      0.00         2\n",
      "      rumors       0.00      0.00      0.00        15\n",
      "   unrelated       0.73      0.22      0.34        36\n",
      "\n",
      "    accuracy                           0.69      1000\n",
      "   macro avg       0.30      0.23      0.24      1000\n",
      "weighted avg       0.60      0.69      0.62      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(dev_category_Y,category_model.predict(dev_X.toarray())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stance = stance_model.predict(test_X)\n",
    "test_category = category_model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'category', 'stance'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "utils.write_test_file(test_ids,test_category,test_stance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models Accuracies:\n",
    "    * Frequency Feature with GaussianNB --> 79.5\n",
    "    * Frequency Feature with SVM --> 77.3\n",
    "    * BOG with MultinomialNB --> 81.9 (without stemming)\n",
    "    * BOG with SVM --> 80.9\n",
    "    * TFIDF with MultinomialNB --> 80.9\n",
    "    * TFIDF with SVM --> 82.0\n",
    "    * TFIDF -> SMOTE -> NAIVE BAYES (alpha=.31) --> fscore = 0.6  acc = 79% "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
